{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport csv\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend as K\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport gc\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T01:02:48.450919Z","iopub.execute_input":"2022-02-28T01:02:48.451254Z","iopub.status.idle":"2022-02-28T01:02:56.486873Z","shell.execute_reply.started":"2022-02-28T01:02:48.451167Z","shell.execute_reply":"2022-02-28T01:02:56.486085Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 1. data preprocessing\n\n\ndf = pd.read_parquet(\"/kaggle/input/ubiquant-parquet/train_low_mem.parquet\")\ndf.head()\n\n#print(df.isnull().sum()) #check whether there is null value\ndf_2 = df.drop('time_id',axis='columns')\ndf_2 = df_2.drop('investment_id',axis='columns')\ndf_2.head()\n\n# #sampling data \n\ny = df_2['target'].values\n# print(y)\nx_columns = df_2.drop('target', axis='columns').drop('row_id',axis='columns') #you can use drop sequently\nx= df[x_columns].values\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state= 123)\n# print(x_test)\n# print(y_test)\n\nprint(np.shape(x_test))\nprint(np.shape(y_test))\nprint(np.shape(x_train))\nprint(np.shape(y_train))\n\n#make train_set and data set","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T01:02:56.488902Z","iopub.execute_input":"2022-02-28T01:02:56.489845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    input = Input(shape=(300,), name = 'input')\n    hidden1 = Dense(256, activation = 'relu', name = 'dense1')(input)\n    hidden2 = Dense(256, activation = 'relu', name = 'dense2')(hidden1)\n    dropout = Dropout(0.3)(hidden2)\n    hidden3 = Dense(128, activation = 'relu', name = 'dense3')(dropout)\n    output = Dense(1, name = 'output')(hidden3)\n    \n    model = Model(inputs=[input], outputs=output)\n    \n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ubiquant\n# env = ubiquant.make_env()   # initialize the environment\n# iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH=300\n\nkf = KFold(5, shuffle=True, random_state = 111) # random_state = consistency\n\nfor (test_df, sample_prediction_df) in iter_test:\n    numpy_test_df=test_df.to_numpy()\n    test_len = numpy_test_df.shape[0]\n    #print(test_len)\n    \n    oos_pred = []\n    append_pred =[]\n    mean_pred = []\n    \n\n    fold = 0\n    while fold <= 5:\n        fold+=1\n        print(f\"Fold #{fold}\")\n\n        model = build_model()\n        early_stopping = EarlyStopping(patience = 50)\n        model.fit(x_train, y_train, batch_size=64, validation_data=(x_test, y_test), epochs = EPOCH, callbacks=[early_stopping])\n\n        pred = model.predict(numpy_test_df[:,2:].astype(float))\n\n        oos_pred.append(pred)\n        print(oos_pred)\n     \n    \n    for j in range(test_len):\n        for k in range(fold): \n            append_pred.append(oos_pred[k][j][-1])\n        mean = np.mean(append_pred)\n        mean_pred.append([mean])\n\n    print(mean_pred)\n    sample_prediction_df['target'] = mean_pred\n    env.predict(sample_prediction_df)   # register your predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}