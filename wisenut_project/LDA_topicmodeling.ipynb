{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ-3IYSGUIms"
      },
      "source": [
        "### **Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPk7gJPGMKfY"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxUjvFJ2Ze0K"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab,Okt\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import csv\n",
        "from pandas import DataFrame \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_wZm6puUXS_"
      },
      "source": [
        "## **Functions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT2KvheRZpjz"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace(\".\", \"\").strip()\n",
        "    text = text.replace(\"·\", \" \").strip()\n",
        "    pattern = '[^ ㄱ-ㅣ가-힣|0-9]+'\n",
        "    text = re.sub(pattern=pattern, repl='', string=text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE0OKUGogJuB"
      },
      "outputs": [],
      "source": [
        "def get_nouns(tokenizer, sentence):\n",
        "    tagged = tokenizer.nouns(sentence)\n",
        "    nouns = [x for x in tagged if len(x) >1]\n",
        "\n",
        "    stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
        "    ebike_stopwords = ['자전거', '생각', '정도', '아주', '사은', '모두','정말','타고','조금','바로','보고','일단','매우','느낌','하나','다시','진짜','한번','대비','자체','약간','사람','듭니','전기자전거','생각','정도','아주','사은','정말','타고','설명','조금','바로','마음','보고','일단','매우','느낌','하나','이상','다시','진짜','한번','대비','자체','약간','사람','듭니','구매','제품','생각','아주','문제','구입','바로','사장','바로','마음','처음','사용','그냥','부분','전기', '여기', '때문', '오늘','다른','살짝','삼천리','팬텀','볼트','다음','해주시','가능','정도', '생각', '사용', '제품', '사진', '장착', '사람', '때문', '라이', '경우', '하나', '이상', '이용', '우리', '확인', '여기', '일반', '감사', '선택', '카페', '추천', '다음', '시작', '우도', '안녕', '이번', '필요', '느낌', '처음', '저희', '문제' ,'추가', '부분', '마음', '하루', '가지', '최고', '화질', '모습', '고민', '재생', '진행', '최대', '마지막', '작업', '동안', '기분', '참고', '카카오' ,'설명' ,'부탁', '커피', '행복', '사고', '이마', '전문', '기준', ' 제공', '포스팅', '스타', '걱정', '포함', '관련', '네이버', '기존', '이야기', '소리', '나라', '적용', '이거', '기억', '지원', '블로그']\n",
        "    \n",
        "    for word in ebike_stopwords:\n",
        "      stopwords.append(word)\n",
        "\n",
        "    nouns = [words for words in nouns if words not in stopwords]\n",
        "    return nouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDNeTezrgJwa"
      },
      "outputs": [],
      "source": [
        "def tokenize(df):\n",
        "    tokenizer = Okt()\n",
        "    processed_data = []\n",
        "    for sent in tqdm(df['내용']):\n",
        "        sentence = clean_text(str(sent).replace(\"\\n\", \"\").strip()) #줄 마다 데이터 전처리\n",
        "        processed_data.append(get_nouns(tokenizer, sentence)) \n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyH7d9KWgJzD"
      },
      "outputs": [],
      "source": [
        "def save_processed_data(processed_data):\n",
        "    with open(\"tokenized_data_jinyard.csv\", 'w', newline=\"\", encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        for data in processed_data:\n",
        "            writer.writerow(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGQ5CC2hUc1D"
      },
      "source": [
        "## **Running Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oInDu7luhTwL"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    df = pd.read_csv(\"/content/elec_bicycle_included.csv\",encoding='utf-8')\n",
        "    processed_data = tokenize(df)\n",
        "    save_processed_data(processed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2QQPoovMdrf",
        "outputId": "d113dd28-6428-431b-bb04-f8ba572daecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "#csv에 저장해놓은 단어들 불러오기\n",
        "\n",
        "\n",
        "import csv\n",
        "\n",
        "with open('/content/tokenized_data_social_mecab.csv', encoding='utf-8', newline='') as f:\n",
        "  next(f)\n",
        "  reader = csv.reader(f)\n",
        "  data = list(reader)\n",
        "\n",
        "print(type(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-OFeiOHUiE4"
      },
      "source": [
        "## **LDA modeling**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EixCbH7hTzG"
      },
      "outputs": [],
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models.callbacks import CoherenceMetric\n",
        "from gensim import corpora\n",
        "from gensim.models.callbacks import PerplexityMetric\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CQMUvZdScN6"
      },
      "outputs": [],
      "source": [
        "dictionary = corpora.Dictionary(data)\n",
        "dictionary.filter_extremes(no_below=2, no_above=0.5) #단어 2번 이하 및 50% 이상 등장 제거\n",
        "corpus = [dictionary.doc2bow(text) for text in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq9gf09Qerwe"
      },
      "outputs": [],
      "source": [
        "#passes -> epoch 반복에 따른 coherence 변화\n",
        "\n",
        "coherences=[]\n",
        "perplexities=[]\n",
        "passes=[]\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "for i in range(7):\n",
        "    \n",
        "    ntopics, nwords = 4, 100\n",
        "    if i==0:\n",
        "        p=1\n",
        "    else:\n",
        "        p=i*5\n",
        "    lda4 = LdaModel(corpus, id2word=dictionary, num_topics=ntopics, iterations=400, passes=p)\n",
        "    print('epoch',p)\n",
        "    # tfidf, corpus 무슨 차이?\n",
        "    # lda = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=ntopics, iterations=200000)\n",
        "\n",
        "    cm = CoherenceModel(model=lda4, corpus=corpus, coherence='u_mass')\n",
        "    coherence = cm.get_coherence()\n",
        "    print(\"Cpherence\",coherence)\n",
        "    coherences.append(coherence)\n",
        "    print('Perplexity: ', lda4.log_perplexity(corpus),'\\n\\n')\n",
        "    perplexities.append(lda4.log_perplexity(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Giz5MiY2ilCy"
      },
      "outputs": [],
      "source": [
        "#결과 시각화\n",
        "\n",
        "for i in range(7):\n",
        "  if i ==0:\n",
        "    passes.append(1)\n",
        "  else:\n",
        "    passes.append(5 * i)\n",
        "\n",
        "plt.plot(passes, coherences)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdpsQMK8T8Fe"
      },
      "outputs": [],
      "source": [
        "plt.plot(passes, perplexities)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glkIKkakhtyd"
      },
      "outputs": [],
      "source": [
        "coherencesT=[]\n",
        "perplexitiesT=[]\n",
        "passes=[]\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "for i in range(7):\n",
        "    \n",
        "    ntopics, nwords = 5, 100\n",
        "    if i==0:\n",
        "        ntopics = 5\n",
        "    else:\n",
        "        ntopics = (5 * (i+1) )\n",
        "    lda4 = LdaModel(corpus, id2word=dictionary, num_topics=ntopics, iterations=400, passes=20)\n",
        "    print('ntopis', ntopics)\n",
        "\n",
        "    cm = CoherenceModel(model=lda4, corpus=corpus, coherence='u_mass')\n",
        "    coherence = cm.get_coherence()\n",
        "    print(\"Cpherence\",coherence)\n",
        "    coherencesT.append(coherence)\n",
        "    print('Perplexity: ', lda4.log_perplexity(corpus),'\\n\\n')\n",
        "    perplexitiesT.append(lda4.log_perplexity(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aodP7MkZqbQB"
      },
      "outputs": [],
      "source": [
        "ntopicT = [5, 10, 15, 20, 25, 30, 35]\n",
        "\n",
        "plt.plot(ntopicT, coherencesT)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sT-b4eaT-08"
      },
      "outputs": [],
      "source": [
        "plt.plot(ntopicT ,  perplexitiesT)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N0DTMJsrOgc"
      },
      "outputs": [],
      "source": [
        "#최종 모델\n",
        "\n",
        "num_topics = 5\n",
        "chunksize = 2000\n",
        "passes = 20\n",
        "iterations = 400\n",
        "eval_every = None\n",
        "\n",
        "temp = dictionary[0]\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    chunksize=chunksize,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    iterations=iterations,\n",
        "    num_topics=num_topics,\n",
        "    passes=passes,\n",
        "    eval_every=eval_every\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAI88eIJnBKs"
      },
      "outputs": [],
      "source": [
        "top_topics = model.top_topics(corpus) #, num_words=20)\n",
        "\n",
        "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
        "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
        "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(top_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9FZutBvUm3p"
      },
      "source": [
        "## **LDA model Visualization**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSfP8_a2pLwV"
      },
      "outputs": [],
      "source": [
        "pip install pyldavis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQu7xEdnnB0o"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgkSODrJnEMM"
      },
      "outputs": [],
      "source": [
        "lda_visualization = gensimvis.prepare(model, corpus, dictionary, sort_topics=False)\n",
        "pyLDAvis.save_html(lda_visualization, 'topic_4_name.html')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LDA_topicmodeling",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
